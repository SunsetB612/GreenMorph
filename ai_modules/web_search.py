"""
Webæœç´¢æ¨¡å—
æ”¯æŒGoogle Search APIã€SerpAPIã€ç™¾åº¦æœç´¢APIã€å¿…åº”æœç´¢APIç­‰
"""

import asyncio
import aiohttp
import hashlib
import time
import urllib.parse
from typing import Optional, List, Dict, Any
from loguru import logger
from app.config import settings


class WebSearchService:
    """ç½‘é¡µæœç´¢æœåŠ¡"""
    
    def __init__(self):
        # åŸæœ‰é…ç½®
        self.google_api_key = settings.google_search_api_key
        self.google_engine_id = settings.google_search_engine_id
        self.serpapi_key = settings.serpapi_key
        self.enable_search = settings.enable_web_search
        
        # å›½å†…æœç´¢APIé…ç½®
        self.baidu_api_key = settings.baidu_search_api_key
        self.baidu_secret_key = settings.baidu_search_secret_key
        self.bing_api_key = settings.bing_search_api_key
        self.sogou_api_key = settings.sogou_search_api_key
        
        # æœç´¢ä¼˜å…ˆçº§é…ç½®
        self.search_priority = settings.search_priority.split(',')
    
    async def search_realistic_renovation_cases(self, item_type: str, materials: List[str], target_style: str) -> List[Dict[str, Any]]:
        """
        æœç´¢ç°å®æ”¹é€ æ¡ˆä¾‹ï¼Œè·å–æ›´å¤šå®ç”¨å‚è€ƒ
        
        Args:
            item_type: ç‰©å“ç±»å‹ï¼ˆå¦‚æ¤…å­ã€æ¡Œå­ç­‰ï¼‰
            materials: ææ–™åˆ—è¡¨
            target_style: ç›®æ ‡é£æ ¼
            
        Returns:
            ç°å®æ”¹é€ æ¡ˆä¾‹åˆ—è¡¨
        """
        if not self.enable_search:
            logger.warning("ç½‘é¡µæœç´¢åŠŸèƒ½å·²ç¦ç”¨")
            return []
        
        # æ„å»ºæ›´å…·ä½“çš„æœç´¢æŸ¥è¯¢
        material_str = " ".join(materials[:3])  # åªå–å‰3ä¸ªææ–™
        queries = [
            f"{item_type} æ”¹é€  DIY å®ç”¨ æ•™ç¨‹",
            f"{item_type} {material_str} æ—§ç‰©æ”¹é€  ç°å®æ¡ˆä¾‹",
            f"{target_style} {item_type} æ”¹é€  æ­¥éª¤ æ•™ç¨‹",
            f"åºŸæ—§ {item_type} æ”¹é€  å®ç”¨ å®¶åº­",
            f"{item_type} æ”¹é€  æˆæœ¬ä½ æ˜“æ“ä½œ"
        ]
        
        all_results = []
        
        for query in queries:
            try:
                logger.info(f"ğŸ” æœç´¢ç°å®æ”¹é€ æ¡ˆä¾‹: {query}")
                results = await self.search(query, num_results=3)
                
                # è¿‡æ»¤å’Œå¢å¼ºç»“æœ
                for result in results:
                    if self._is_realistic_case(result):
                        result['search_query'] = query
                        result['relevance_score'] = self._calculate_relevance(result, item_type, materials, target_style)
                        all_results.append(result)
                
                # é¿å…é‡å¤æœç´¢
                if len(all_results) >= 8:
                    break
                    
            except Exception as e:
                logger.warning(f"æœç´¢æŸ¥è¯¢å¤±è´¥: {query}, é”™è¯¯: {e}")
                continue
        
        # æŒ‰ç›¸å…³æ€§æ’åºå¹¶å»é‡
        unique_results = self._deduplicate_results(all_results)
        sorted_results = sorted(unique_results, key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        logger.info(f"âœ… æ‰¾åˆ° {len(sorted_results)} ä¸ªç°å®æ”¹é€ æ¡ˆä¾‹")
        return sorted_results[:8]  # è¿”å›æœ€å¤š8ä¸ªæœ€ç›¸å…³çš„æ¡ˆä¾‹
    
    def _is_realistic_case(self, result: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç°å®æ”¹é€ æ¡ˆä¾‹"""
        title = result.get('title', '').lower()
        snippet = result.get('snippet', '').lower()
        
        # ç°å®æ”¹é€ æ¡ˆä¾‹çš„å…³é”®è¯
        realistic_keywords = [
            'diy', 'æ•™ç¨‹', 'æ­¥éª¤', 'å®ç”¨', 'ç®€å•', 'æ˜“æ“ä½œ', 'æˆæœ¬ä½',
            'å®¶åº­', 'æ”¹é€ ', 'ç¿»æ–°', 'ä¿®å¤', 'å†åˆ©ç”¨', 'ç¯ä¿',
            'å·¥å…·', 'ææ–™', 'æ—¶é—´', 'éš¾åº¦', 'å®‰å…¨'
        ]
        
        # é¿å…çš„è¯æ±‡ï¼ˆè¿‡äºç†æƒ³åŒ–æˆ–ä¸ç°å®çš„ï¼‰
        unrealistic_keywords = [
            'è‰ºæœ¯', 'åˆ›æ„', 'æ¦‚å¿µ', 'è®¾è®¡', 'å±•ç¤º', 'å±•è§ˆ',
            'ä¸“ä¸š', 'å¤æ‚', 'æ˜‚è´µ', 'é«˜ç«¯', 'å®šåˆ¶'
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç°å®å…³é”®è¯
        has_realistic = any(keyword in title or keyword in snippet for keyword in realistic_keywords)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸ç°å®å…³é”®è¯
        has_unrealistic = any(keyword in title or keyword in snippet for keyword in unrealistic_keywords)
        
        return has_realistic and not has_unrealistic
    
    def _calculate_relevance(self, result: Dict[str, Any], item_type: str, materials: List[str], target_style: str) -> float:
        """è®¡ç®—æœç´¢ç»“æœçš„ç›¸å…³æ€§åˆ†æ•°"""
        title = result.get('title', '').lower()
        snippet = result.get('snippet', '').lower()
        text = f"{title} {snippet}"
        
        score = 0.0
        
        # ç‰©å“ç±»å‹åŒ¹é…
        if item_type.lower() in text:
            score += 2.0
        
        # ææ–™åŒ¹é…
        for material in materials:
            if material.lower() in text:
                score += 1.0
        
        # é£æ ¼åŒ¹é…
        if target_style.lower() in text:
            score += 1.5
        
        # ç°å®æ€§å…³é”®è¯åŠ åˆ†
        realistic_bonus = [
            'diy', 'æ•™ç¨‹', 'æ­¥éª¤', 'å®ç”¨', 'ç®€å•', 'æˆæœ¬ä½',
            'å·¥å…·', 'ææ–™', 'æ—¶é—´', 'å®‰å…¨'
        ]
        
        for keyword in realistic_bonus:
            if keyword in text:
                score += 0.5
        
        return score
    
    def _deduplicate_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é‡æœç´¢ç»“æœ"""
        seen_urls = set()
        unique_results = []
        
        for result in results:
            url = result.get('url', '')
            if url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
        
        return unique_results
    
    async def search(self, query: str, num_results: int = 5) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œç½‘é¡µæœç´¢
        
        Args:
            query: æœç´¢å…³é”®è¯
            num_results: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.enable_search:
            logger.warning("ç½‘é¡µæœç´¢åŠŸèƒ½å·²ç¦ç”¨")
            return []
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„æœç´¢API
        for search_provider in self.search_priority:
            search_provider = search_provider.strip()
            
            try:
                if search_provider == "baidu" and self.baidu_api_key and self.baidu_secret_key:
                    logger.info(f"ğŸ” å°è¯•ä½¿ç”¨ç™¾åº¦æœç´¢API: {query}")
                    result = await self._baidu_search(query, num_results)
                    if result:
                        return result
                        
                elif search_provider == "bing" and self.bing_api_key:
                    logger.info(f"ğŸ” å°è¯•ä½¿ç”¨å¿…åº”æœç´¢API: {query}")
                    result = await self._bing_search(query, num_results)
                    if result:
                        return result
                        
                elif search_provider == "google" and self.google_api_key and self.google_engine_id:
                    logger.info(f"ğŸ” å°è¯•ä½¿ç”¨Googleæœç´¢API: {query}")
                    result = await self._google_search(query, num_results)
                    if result:
                        return result
                        
                elif search_provider == "serpapi" and self.serpapi_key:
                    logger.info(f"ğŸ” å°è¯•ä½¿ç”¨SerpAPI: {query}")
                    result = await self._serpapi_search(query, num_results)
                    if result:
                        return result
                        
            except Exception as e:
                logger.warning(f"âŒ {search_provider}æœç´¢å¤±è´¥: {e}")
                continue
        
        logger.warning("âŒ æ‰€æœ‰æœç´¢APIéƒ½ä¸å¯ç”¨")
        return []
    
    async def _google_search(self, query: str, num_results: int) -> List[Dict[str, Any]]:
        """ä½¿ç”¨Google Custom Search API"""
        try:
            from googleapiclient.discovery import build
            
            logger.info(f"ğŸ” ä½¿ç”¨Google Search APIæœç´¢: {query}")
            
            # æ„å»ºæœç´¢æœåŠ¡
            service = build("customsearch", "v1", developerKey=self.google_api_key)
            
            # æ‰§è¡Œæœç´¢
            result = service.cse().list(
                q=query,
                cx=self.google_engine_id,
                num=min(num_results, 10),  # Google APIæœ€å¤šè¿”å›10ä¸ªç»“æœ
                lr='lang_zh-CN|lang_en',  # ä¸­è‹±æ–‡ç»“æœ
                safe='active'  # å®‰å…¨æœç´¢
            ).execute()
            
            # è§£æç»“æœ
            search_results = []
            for item in result.get('items', []):
                search_results.append({
                    'title': item.get('title', ''),
                    'link': item.get('link', ''),
                    'snippet': item.get('snippet', ''),
                    'source': 'google'
                })
            
            logger.info(f"âœ… Googleæœç´¢å®Œæˆï¼Œè·å–åˆ° {len(search_results)} ä¸ªç»“æœ")
            return search_results
            
        except Exception as e:
            logger.error(f"âŒ Googleæœç´¢å¤±è´¥: {e}")
            return []
    
    async def _serpapi_search(self, query: str, num_results: int) -> List[Dict[str, Any]]:
        """ä½¿ç”¨SerpAPI"""
        try:
            import requests
            
            logger.info(f"ğŸ” ä½¿ç”¨SerpAPIæœç´¢: {query}")
            
            # é…ç½®æœç´¢å‚æ•°
            params = {
                "engine": "google",
                "q": query,
                "api_key": self.serpapi_key,
                "num": min(num_results, 10),
                "hl": "zh-cn",  # ä¸­æ–‡ç•Œé¢
                "gl": "cn"      # ä¸­å›½åœ°åŒº
            }
            
            # ä½¿ç”¨requestsç›´æ¥è°ƒç”¨SerpAPI
            url = "https://serpapi.com/search"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # è§£æç»“æœ
                        search_results = []
                        for item in data.get('organic_results', []):
                            search_results.append({
                                'title': item.get('title', ''),
                                'link': item.get('link', ''),
                                'snippet': item.get('snippet', ''),
                                'source': 'serpapi'
                            })
                        
                        logger.info(f"âœ… SerpAPIæœç´¢å®Œæˆï¼Œè·å–åˆ° {len(search_results)} ä¸ªç»“æœ")
                        return search_results
                    else:
                        logger.error(f"âŒ SerpAPIè¿”å›é”™è¯¯çŠ¶æ€: {response.status}")
                        return []
                        
        except Exception as e:
            logger.error(f"âŒ SerpAPIæœç´¢å¤±è´¥: {e}")
            return []
    
    async def _baidu_search(self, query: str, num_results: int) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ç™¾åº¦æœç´¢API"""
        try:
            import requests
            
            logger.info(f"ğŸ” ä½¿ç”¨ç™¾åº¦æœç´¢API: {query}")
            
            # ç™¾åº¦æœç´¢APIéœ€è¦ç­¾åéªŒè¯
            timestamp = str(int(time.time()))
            sign_string = f"{self.baidu_api_key}{query}{timestamp}{self.baidu_secret_key}"
            sign = hashlib.md5(sign_string.encode('utf-8')).hexdigest()
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                'q': query,
                'timestamp': timestamp,
                'apikey': self.baidu_api_key,
                'sign': sign,
                'rn': min(num_results, 10),  # ç»“æœæ•°é‡
                'format': 'json'
            }
            
            # å‘é€è¯·æ±‚
            url = "https://api.baidu.com/json/sms/service/v2/search"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # è§£æç™¾åº¦æœç´¢ç»“æœ
                        search_results = []
                        if 'data' in data and 'results' in data['data']:
                            for item in data['data']['results'][:num_results]:
                                search_results.append({
                                    'title': item.get('title', ''),
                                    'link': item.get('url', ''),
                                    'snippet': item.get('content', ''),
                                    'source': 'baidu'
                                })
                        
                        logger.info(f"âœ… ç™¾åº¦æœç´¢å®Œæˆï¼Œè·å–åˆ° {len(search_results)} ä¸ªç»“æœ")
                        return search_results
                    else:
                        logger.error(f"âŒ ç™¾åº¦æœç´¢APIè¿”å›é”™è¯¯çŠ¶æ€: {response.status}")
                        return []
                        
        except Exception as e:
            logger.error(f"âŒ ç™¾åº¦æœç´¢å¤±è´¥: {e}")
            return []
    
    async def _bing_search(self, query: str, num_results: int) -> List[Dict[str, Any]]:
        """ä½¿ç”¨å¿…åº”æœç´¢API"""
        try:
            logger.info(f"ğŸ” ä½¿ç”¨å¿…åº”æœç´¢API: {query}")
            
            # å¿…åº”æœç´¢API v7
            url = "https://api.bing.microsoft.com/v7.0/search"
            headers = {
                'Ocp-Apim-Subscription-Key': self.bing_api_key,
                'Content-Type': 'application/json'
            }
            params = {
                'q': query,
                'count': min(num_results, 50),  # å¿…åº”APIæœ€å¤šè¿”å›50ä¸ªç»“æœ
                'mkt': 'zh-CN',  # ä¸­æ–‡å¸‚åœº
                'safeSearch': 'Moderate'  # å®‰å…¨æœç´¢
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # è§£æå¿…åº”æœç´¢ç»“æœ
                        search_results = []
                        if 'webPages' in data and 'value' in data['webPages']:
                            for item in data['webPages']['value'][:num_results]:
                                search_results.append({
                                    'title': item.get('name', ''),
                                    'link': item.get('url', ''),
                                    'snippet': item.get('snippet', ''),
                                    'source': 'bing'
                                })
                        
                        logger.info(f"âœ… å¿…åº”æœç´¢å®Œæˆï¼Œè·å–åˆ° {len(search_results)} ä¸ªç»“æœ")
                        return search_results
                    else:
                        logger.error(f"âŒ å¿…åº”æœç´¢APIè¿”å›é”™è¯¯çŠ¶æ€: {response.status}")
                        return []
                        
        except Exception as e:
            logger.error(f"âŒ å¿…åº”æœç´¢å¤±è´¥: {e}")
            return []
    
    async def search_text_only(self, query: str, num_results: int = 5) -> str:
        """
        æœç´¢å¹¶è¿”å›çº¯æ–‡æœ¬ç»“æœ
        
        Args:
            query: æœç´¢å…³é”®è¯
            num_results: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            åˆå¹¶çš„æœç´¢ç»“æœæ–‡æœ¬
        """
        results = await self.search(query, num_results)
        
        if not results:
            return ""
        
        # åˆå¹¶æœç´¢ç»“æœä¸ºæ–‡æœ¬
        text_results = []
        for result in results:
            title = result.get('title', '')
            snippet = result.get('snippet', '')
            if title and snippet:
                text_results.append(f"{title}: {snippet}")
        
        return '\n'.join(text_results)


# å…¨å±€æœç´¢æœåŠ¡å®ä¾‹
web_search_service = WebSearchService()


async def web_search(search_term: str, explanation: str = "", num_results: int = 5) -> str:
    """
    ç½‘é¡µæœç´¢å‡½æ•°ï¼ˆå…¼å®¹ç°æœ‰æ¥å£ï¼‰
    
    Args:
        search_term: æœç´¢å…³é”®è¯
        explanation: æœç´¢è¯´æ˜ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        num_results: è¿”å›ç»“æœæ•°é‡
        
    Returns:
        æœç´¢ç»“æœæ–‡æœ¬
    """
    logger.info(f"ğŸ” ç½‘é¡µæœç´¢: {search_term} ({explanation})")
    
    try:
        result = await web_search_service.search_text_only(search_term, num_results)
        
        if result:
            logger.info(f"âœ… æœç´¢æˆåŠŸï¼Œè·å–åˆ°å†…å®¹é•¿åº¦: {len(result)} å­—ç¬¦")
        else:
            logger.warning("âš ï¸ æœç´¢æœªè¿”å›æœ‰æ•ˆç»“æœ")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ ç½‘é¡µæœç´¢å¼‚å¸¸: {e}")
        return ""
